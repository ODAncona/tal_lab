{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger l'archive `UD_French-GSD-withBlankLines.zip` fournie sur Cyberlearn.\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu des colonnes :\n",
      "     Colonne 0 : Index\n",
      "     Colonne 1 : Token\n",
      "     Colonne 2 : Lemma\n",
      "     Colonne 3 : POS\n",
      "Liste des POS TAGS du projet Universal Dependencies:\n",
      "https://universaldependencies.org/u/pos/\n",
      "Format des fichiers du projet Universal Dependencies:\n",
      "https://universaldependencies.org/format.html\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule.\n",
    "cols = {'0': 'Index', '1': 'Token', '2': 'Lemma', '3': 'POS'}\n",
    "url_pos = \"https://universaldependencies.org/u/pos/\"\n",
    "url_format = \"https://universaldependencies.org/format.html\"\n",
    "\n",
    "print(\"Contenu des colonnes :\")\n",
    "\n",
    "for key, value in cols.items():\n",
    "    print(\"     Colonne\", key, \":\", value)\n",
    "\n",
    "print(\"Liste des POS TAGS du projet Universal Dependencies:\")\n",
    "print(url_pos)\n",
    "\n",
    "print(\"Format des fichiers du projet Universal Dependencies:\")\n",
    "print(url_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "              Corpus d'entraînement               \n",
      "__________________________________________________\n",
      "    Il y a 366371 tokens dans ce corpus.\n",
      "    Il y a 14554 phrases dans ce corpus.\n",
      "__________________________________________________\n",
      "             Corpus de développement              \n",
      "__________________________________________________\n",
      "    Il y a 36830 tokens dans ce corpus.\n",
      "    Il y a 1478 phrases dans ce corpus.\n",
      "__________________________________________________\n",
      "                  Corpus de test                  \n",
      "__________________________________________________\n",
      "    Il y a 10298 tokens dans ce corpus.\n",
      "    Il y a 416 phrases dans ce corpus.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "# Utilitaire pour afficher un titre\n",
    "def print_title(str, char, size):\n",
    "    print(f\"{'':{char}^{size}}\")\n",
    "    print(f\"{str:^{size}}\")\n",
    "    print(f\"{'':{char}^{size}}\")\n",
    "\n",
    "# Fichiers de travail\n",
    "file_location = 'UD_French-GSD-withBlankLines'\n",
    "file_train = 'fr-ud-train.conllu3'\n",
    "file_dev = 'fr-ud-dev.conllu3'\n",
    "file_test = 'fr-ud-test.conllu3'\n",
    "\n",
    "# Lecture des fichiers\n",
    "columnsIgnore = ('ignore', 'words', 'ignore', 'pos')\n",
    "train_corpus = ConllCorpusReader(file_location, file_train, columntypes=columnsIgnore, separator='\\t')\n",
    "dev_corpus = ConllCorpusReader(file_location, file_dev, columntypes=columnsIgnore, separator='\\t')\n",
    "test_corpus = ConllCorpusReader(file_location, file_test, columntypes=columnsIgnore, separator='\\t')\n",
    "corpuses = {'train': train_corpus, 'dev': dev_corpus, 'test': test_corpus}\n",
    "\n",
    "print_title(\"Corpus d'entraînement\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['train'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['train'].sents())} phrases dans ce corpus.\")\n",
    "print_title(\"Corpus de développement\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['dev'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['dev'].sents())} phrases dans ce corpus.\")\n",
    "print_title(\"Corpus de test\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['test'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['test'].sents())} phrases dans ce corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.3 sec].\n",
      "Tagged 36830 words at 30016.30 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 1478 sentences and 36830 words, of which 3049 were unknown.\n",
      "Total sentences right: 144 (9.742896%); wrong: 1334 (90.257104%).\n",
      "Total tags right: 32360 (87.863155%); wrong: 4470 (12.136845%).\n",
      "Unknown words right: 2232 (73.204329%); wrong: 817 (26.795671%).\n"
     ]
    }
   ],
   "source": [
    "! java \\\n",
    "    -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model french-ud.tagger \\\n",
    "    -testFile \"format=TSV,wordColumn=1,tagColumn=3,UD_French-GSD-withBlankLines/fr-ud-dev.conllu3\"\\\n",
    "    -verboseResults false\n",
    "\n",
    "# Total sentences   right: 144   (9.742896%);    wrong: 1334 (90.257104%).\n",
    "# Total tags        right: 32360 (87.863155%);   wrong: 4470 (12.136845%).\n",
    "# Unknown words     right: 2232  (73.204329%);   wrong: 817  (26.795671%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.4 sec].\n",
      "Tagged 10298 words at 15965.89 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 416 sentences and 10298 words, of which 697 were unknown.\n",
      "Total sentences right: 54 (12.980769%); wrong: 362 (87.019231%).\n",
      "Total tags right: 8960 (87.007186%); wrong: 1338 (12.992814%).\n",
      "Unknown words right: 487 (69.870875%); wrong: 210 (30.129125%).\n"
     ]
    }
   ],
   "source": [
    "! java \\\n",
    "    -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model french-ud.tagger \\\n",
    "    -testFile \"format=TSV,wordColumn=1,tagColumn=3,UD_French-GSD-withBlankLines/fr-ud-test.conllu3\"\\\n",
    "    -verboseResults false\n",
    "\n",
    "# Total sentences   right: 54   (12.980769%);    wrong: 362  (87.019231%).\n",
    "# Total tags        right: 8960 (87.007186%);    wrong: 1338 (12.992814%).\n",
    "# Unknown words     right: 487  (69.870875%);    wrong: 210  (30.129125%)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiaire** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "              Corpus d'entraînement               \n",
      "__________________________________________________\n",
      "Il y a 36830 mots dans le corpus de développement.\n",
      "Il y a 1478 phrases dans le corpus de développement.\n",
      "Le tagger a trouvé 32360 tokens corrects sur 36830, soit 87.86%.\n",
      "__________________________________________________\n",
      "                  Corpus de test                  \n",
      "__________________________________________________\n",
      "Il y a 10298 mots dans le corpus de test.\n",
      "Il y a 416 phrases dans le corpus de test.\n",
      "Le tagger a trouvé 8960 tokens corrects sur 10298, soit 87.01%.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire vos réponses ci-dessous, en commentaires\n",
    "print_title(\"Corpus d'entraînement\", \"_\", 50)\n",
    "print(f\"Il y a {len(corpuses['dev'].words())} mots dans le corpus de développement.\")\n",
    "print(f\"Il y a {len(corpuses['dev'].sents())} phrases dans le corpus de développement.\")\n",
    "print(f\"Le tagger a trouvé 32360 tokens corrects sur 36830, soit 87.86%.\")\n",
    "print_title(\"Corpus de test\", \"_\", 50)\n",
    "print(f\"Il y a {len(corpuses['test'].words())} mots dans le corpus de test.\")\n",
    "print(f\"Il y a {len(corpuses['test'].sents())} phrases dans le corpus de test.\")\n",
    "print(f\"Le tagger a trouvé 8960 tokens corrects sur 10298, soit 87.01%.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le tagger fonctionne relativement bien avec plus de 87% des mots correctement tagués. Il est assez impressionnant de voir que la précision sur les mots inconnus est d'environ 70%. De plus, on remarque que le taux de phrases entièrement correcte est d'environ 10% ce qui reste faible. Ainsi, même si la précision sur les mots est relativement bonne, le tagger commet tout de même des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérience 1: Entraîner le modèle, recherche qn\n",
    "! java \\\n",
    "    -cp stanford-postagger.jar     edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -props labo_hyper_parameter_1.props \\\n",
    "    -nthreads 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## tagger training invoked at Mon Mar 13 15:48:12 CET 2023 with arguments:\n",
      "                   model = experiment2.tagger\n",
      "                    arch = left3words,naacl2003unknowns,unicodeshapes(-1,1)\n",
      "            wordFunction = \n",
      "               trainFile = format=TSV,wordColumn=1,tagColumn=3,UD_French-GSD-withBlankLines/fr-ud-train.conllu3\n",
      "         closedClassTags = \n",
      " closedClassTagThreshold = 40\n",
      " curWordMinFeatureThresh = 2\n",
      "                   debug = false\n",
      "             debugPrefix = \n",
      "            tagSeparator = _\n",
      "                encoding = utf-8\n",
      "              iterations = 100\n",
      "                    lang = french\n",
      "    learnClosedClassTags = false\n",
      "        minFeatureThresh = 2\n",
      "           openClassTags = \n",
      "rareWordMinFeatureThresh = 10\n",
      "          rareWordThresh = 5\n",
      "                  search = qn\n",
      "                    sgml = false\n",
      "            sigmaSquared = 0.0\n",
      "                   regL1 = 0.75\n",
      "               tagInside = \n",
      "                tokenize = true\n",
      "        tokenizerFactory = \n",
      "        tokenizerOptions = asciiQuotes\n",
      "                 verbose = false\n",
      "          verboseResults = true\n",
      "    veryCommonWordThresh = 250\n",
      "                xmlInput = null\n",
      "              outputFile = \n",
      "            outputFormat = slashTags\n",
      "     outputFormatOptions = \n",
      "                nthreads = 8\n",
      "TaggerExperiments: adding word/tags\n",
      "Loading tagged words from UD_French-GSD-withBlankLines/fr-ud-train.conllu3\n",
      "Read 366371 words from UD_French-GSD-withBlankLines/fr-ud-train.conllu3 [done].\n",
      "Read 14554 sentences, min 2 words, max 404 words.\n",
      "Featurizing tagged data tokens...\n",
      "Featurized 380925 data tokens [done].\n",
      "xSize [num Phi templates] = 305182; ySize [num classes] = 19\n",
      "Hashing histories ...\n",
      "Hashed 305182 histories.\n",
      "Hashing populated histories ...\n",
      "Hashed populated histories.\n",
      "TaggerExperiments.getFeaturesNew: initializing fnumArr.\n",
      "  length of sTemplates keys: 449036\n",
      "getFeaturesNew adding features ...\n",
      "  total feats: 449036, populated: 107016\n",
      "  Max features per x,y pair: 33\n",
      "  Max non-zero y values for an x: 19\n",
      "  Number of non-zero feature x,y pairs: 5563948\n",
      "  Number of zero feature x,y pairs: 234510\n",
      "end getFeaturesNew.\n",
      "Samples from format=TSV,wordColumn=1,tagColumn=3,UD_French-GSD-withBlankLines/fr-ud-train.conllu3\n",
      "Number of features: 107016\n",
      "Tag set: [AUX, PRON, CCONJ, PROPN, SYM, ADJ, NUM, SCONJ, ADP, DET, ADV, PUNCT, .$$., PART, VERB, X, INTJ, NOUN, _]\n",
      " pcond initialized \n",
      " zlambda initialized \n",
      " ftildeArr initialized \n",
      "QNMinimizer called on double function of 107016 variables, using M = 10.\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 0: neg. log cond. likelihood = 1121610.4181367664 [1 calls to valueAt]\n",
      "               An explanation of the output:\n",
      "Iter           The number of iterations\n",
      "evals          The number of function evaluations\n",
      "SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "LINESEARCH     [## M steplength]  Minpack linesearch\n",
      "                   1-Function value was too high\n",
      "                   2-Value ok, gradient positive, positive curvature\n",
      "                   3-Value ok, gradient negative, positive curvature\n",
      "                   4-Value ok, gradient negative, negative curvature\n",
      "               [.. B]  Backtracking\n",
      "VALUE          The current function value\n",
      "TIME           Total elapsed time\n",
      "|GNORM|        The current norm of the gradient\n",
      "{RELNORM}      The ratio of the current to initial gradient norms\n",
      "AVEIMPROVE     The average improvement / current value\n",
      "EVALSCORE      The last available eval score\n",
      " \n",
      "Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
      "\n",
      "lambda 2 too big: -263.2473684210715\n",
      "lambda 558 too big: -201.6578947367028\n",
      "lambda 1372 too big: 463.69473684195685\n",
      "lambda 1916 too big: -347.0473684212893\n",
      "lambda 1950 too big: -317.94736842121426\n",
      "lambda 2268 too big: -202.15789473670202\n",
      "lambda 2352 too big: -206.35789473670235\n",
      "lambda 2419 too big: 3982.73684210682\n",
      "lambda 2535 too big: 834.3578947389783\n",
      "lambda 2936 too big: 432.7263157893893\n",
      "lambda 3020 too big: 2225.5263157898903\n",
      "lambda 3232 too big: 408.77368421045753\n",
      "lambda 3521 too big: 269.64210526313786\n",
      "lambda 4054 too big: 370.0210526315484\n",
      "lambda 4199 too big: 1150.5263157906409\n",
      "lambda 4728 too big: 227.19999999992694\n",
      "lambda 5394 too big: 489.7789473682203\n",
      "lambda 5576 too big: 202.53157894712717\n",
      "lambda 5640 too big: 426.9789473683509\n",
      "lambda 6436 too big: 539.72631578933\n",
      "lambda 6582 too big: -204.1263157893502\n",
      "lambda 7304 too big: 236.089473684068\n",
      "lambda 7412 too big: -339.74736842127055\n",
      "lambda 7949 too big: 503.49999999987153\n",
      "lambda 8694 too big: 267.77368421016513\n",
      "lambda 9119 too big: 448.2684210524157\n",
      "lambda 9976 too big: -271.36315789478084\n",
      "lambda 10196 too big: 370.02105263157796\n",
      "lambda 10415 too big: 227.19999999992694\n",
      "lambda 10761 too big: 269.64210526313326\n",
      "lambda 11325 too big: 872.073684212596\n",
      "lambda 11628 too big: 520.0052631577945\n",
      "lambda 11637 too big: 621.9578947364776\n",
      "lambda 11755 too big: -287.5631578948227\n",
      "lambda 11835 too big: 1158.2210526322197\n",
      "lambda 11843 too big: 816.2105263162437\n",
      "lambda 12047 too big: 762.0473684221865\n",
      "lambda 12706 too big: 245.68421052624336\n",
      "lambda 13068 too big: 328.6157894736503\n",
      "lambda 13379 too big: 863.6000000004938\n",
      "lambda 13660 too big: -202.0578947367022\n",
      "lambda 13727 too big: -201.2578947367034\n",
      "lambda 14057 too big: -213.8473684209148\n",
      "lambda 14060 too big: 706.3526315814662\n",
      "lambda 14062 too big: 1610.4526315830892\n",
      "lambda 14868 too big: 636.494736841892\n",
      "lambda 14918 too big: 240.51578947360156\n",
      "lambda 15698 too big: 433.92105263106544\n",
      "lambda 16446 too big: 1378.799999999999\n",
      "lambda 17139 too big: 506.27368421052637\n",
      "lambda 18687 too big: 233.84210526300177\n",
      "lambda 19370 too big: 1021.4736842126545\n",
      "lambda 19488 too big: -223.66842105254733\n",
      "lambda 19725 too big: 1555.3157894748947\n",
      "lambda 20155 too big: -223.06842105254574\n",
      "lambda 22412 too big: 564.3421052626298\n",
      "lambda 22842 too big: 308.83684210512064\n",
      "lambda 22974 too big: -204.75789473669832\n",
      "lambda 23174 too big: 520.4315789472305\n",
      "lambda 23219 too big: 747.4631578947233\n",
      "lambda 23393 too big: -350.247368421297\n",
      "lambda 23451 too big: 346.22631578941434\n",
      "lambda 23888 too big: 205.16842105252314\n",
      "lambda 23895 too big: 478.3736842101146\n",
      "lambda 24836 too big: 561.4315789471174\n",
      "lambda 26253 too big: 767.5052631584442\n",
      "lambda 27303 too big: -205.62631578935213\n",
      "lambda 27446 too big: 440.8842105261406\n",
      "lambda 27883 too big: -287.363157894822\n",
      "lambda 27885 too big: -233.3631578946756\n",
      "lambda 28096 too big: 203.99999999993227\n",
      "lambda 28574 too big: 920.1421052634593\n",
      "lambda 29163 too big: 463.69999999985157\n",
      "lambda 29494 too big: -205.15789473669918\n",
      "lambda 29639 too big: 733.2263157894245\n",
      "lambda 29789 too big: -206.35789473670235\n",
      "lambda 30307 too big: -349.04736842129387\n",
      "lambda 30413 too big: -299.40526315801407\n",
      "lambda 30984 too big: -345.64736842128553\n",
      "lambda 32476 too big: 332.58421052615057\n",
      "lambda 32554 too big: 423.53684210508504\n",
      "lambda 32747 too big: 227.19473684203217\n",
      "lambda 33194 too big: 605.9210526311425\n",
      "lambda 33240 too big: -279.9052631579645\n",
      "lambda 33267 too big: 478.1052631575765\n",
      "lambda 33491 too big: 1232.0736842118501\n",
      "lambda 33503 too big: 1021.4736842126545\n",
      "lambda 34051 too big: -206.25789473670204\n",
      "lambda 34333 too big: -205.226315789351\n",
      "lambda 34663 too big: 924.4421052631596\n",
      "lambda 34843 too big: -287.7631578948231\n",
      "lambda 34844 too big: -282.1631578948085\n",
      "lambda 35058 too big: 643.7105263156889\n",
      "lambda 35065 too big: 796.421052631913\n",
      "lambda 35263 too big: 424.705263157807\n",
      "lambda 35994 too big: 275.20526315786185\n",
      "lambda 36355 too big: 325.6263157892461\n",
      "lambda 36503 too big: 230.25789473680948\n",
      "lambda 36729 too big: 325.51578947357075\n",
      "lambda 37875 too big: 1271.2736842105267\n",
      "lambda 38033 too big: 209.63684210520933\n",
      "lambda 38128 too big: 274.1157894736588\n",
      "lambda 39513 too big: -267.047368421081\n",
      "lambda 39796 too big: 761.2421052651991\n",
      "lambda 39843 too big: -286.7631578948203\n",
      "lambda 40072 too big: 767.5052631584442\n",
      "lambda 40243 too big: -224.56842105254992\n",
      "lambda 40944 too big: 463.69999999985157\n",
      "lambda 41270 too big: -247.16315789471423\n",
      "lambda 41790 too big: 275.99473684204503\n",
      "lambda 42843 too big: 1271.05789473806\n",
      "lambda 42996 too big: 1378.7947368421044\n",
      "lambda 43043 too big: 462.7947368414591\n",
      "lambda 45232 too big: -287.363157894822\n",
      "lambda 45628 too big: 465.4947368418538\n",
      "lambda 45640 too big: 409.5736842103262\n",
      "lambda 46156 too big: 474.3368421051832\n",
      "lambda 46313 too big: 1329.84210526599\n",
      "lambda 46536 too big: -203.6684210524953\n",
      "lambda 46588 too big: -223.46842105254683\n",
      "lambda 48454 too big: 240.97368421049046\n",
      "lambda 49096 too big: 267.77368421016513\n",
      "lambda 49100 too big: 931.9315789486104\n",
      "lambda 49175 too big: 239.02105263155073\n",
      "lambda 49238 too big: 313.72631578942134\n",
      "lambda 49260 too big: 214.6157894736071\n",
      "lambda 50482 too big: 1068.6315789501523\n",
      "lambda 50484 too big: 538.9315789468377\n",
      "lambda 51433 too big: -218.16842105253215\n",
      "lambda 51626 too big: 257.57368421036443\n",
      "lambda 52405 too big: 402.96315789465297\n",
      "lambda 52460 too big: 487.7947368418225\n",
      "lambda 52937 too big: 1206.6210526340867\n",
      "lambda 53845 too big: 200.84210526315306\n",
      "lambda 54239 too big: 572.4105263156513\n",
      "lambda 54436 too big: 297.71052631570154\n",
      "lambda 55608 too big: 235.25263157888492\n",
      "lambda 55874 too big: 399.16842105242637\n",
      "lambda 55916 too big: 433.92105263106544\n",
      "lambda 57126 too big: 352.80526315774426\n",
      "lambda 58373 too big: 287.18947368419117\n",
      "lambda 59270 too big: 468.1315789468101\n",
      "lambda 59811 too big: 1655.5315789486683\n",
      "lambda 61960 too big: 213.03684210462384\n",
      "lambda 62255 too big: 564.3421052626298\n",
      "lambda 62709 too big: -204.75789473669832\n",
      "lambda 63022 too big: 244.71578947361346\n",
      "lambda 63434 too big: 424.34736842062534\n",
      "lambda 65345 too big: 2090.4315789484403\n",
      "lambda 67726 too big: -201.6578947367028\n",
      "lambda 68612 too big: 212.23684210513125\n",
      "lambda 69310 too big: -202.15789473670202\n",
      "lambda 69410 too big: -206.35789473670235\n",
      "lambda 70860 too big: 302.9157894735995\n",
      "lambda 71262 too big: 2588.4947368445182\n",
      "lambda 72259 too big: 298.8052631576414\n",
      "lambda 72596 too big: 489.7789473682203\n",
      "lambda 72867 too big: -293.2052631579989\n",
      "lambda 72922 too big: -300.605263158017\n",
      "lambda 74660 too big: 1362.700000000592\n",
      "lambda 75634 too big: -287.1631578948215\n",
      "lambda 77192 too big: 253.00526315765333\n",
      "lambda 77214 too big: -213.90526315778422\n",
      "lambda 77219 too big: -259.7052631579101\n",
      "lambda 77221 too big: -247.50526315787602\n",
      "lambda 77269 too big: -272.2052631579442\n",
      "lambda 78209 too big: -298.3052631580114\n",
      "lambda 78210 too big: -292.80526315799784\n",
      "lambda 79303 too big: 452.97368421011015\n",
      "lambda 79580 too big: 245.68421052624336\n",
      "lambda 79776 too big: 507.4421052629366\n",
      "lambda 79862 too big: -262.7631578947589\n",
      "lambda 80445 too big: -202.0578947367022\n",
      "lambda 80482 too big: -201.2578947367034\n",
      "lambda 81583 too big: 248.87368421051062\n",
      "lambda 82112 too big: 322.87894736829577\n",
      "lambda 82221 too big: 241.98947368418703\n",
      "lambda 82622 too big: 235.42631578928632\n",
      "lambda 85649 too big: 298.8052631576414\n",
      "lambda 85732 too big: 219.16842105252474\n",
      "lambda 85973 too big: 1329.84210526599\n",
      "lambda 86503 too big: -286.06315789481874\n",
      "lambda 86671 too big: 236.27368421051466\n",
      "lambda 87283 too big: 214.62105263154572\n",
      "lambda 89084 too big: 999.3473684232691\n",
      "lambda 89089 too big: 338.47368421048344\n",
      "lambda 91490 too big: 426.4315789472205\n",
      "lambda 92094 too big: 452.97368421011015\n",
      "lambda 92400 too big: 1206.6210526340867\n",
      "lambda 92932 too big: 258.0842105261659\n",
      "lambda 95082 too big: 1580.5894736852003\n",
      "lambda 95097 too big: 1273.073684211125\n",
      "lambda 95102 too big: 210.22105263155572\n",
      "lambda 95103 too big: 209.4631578947157\n",
      "lambda 95143 too big: 961.9526315832884\n",
      "lambda 95542 too big: 450.32631578938447\n",
      "lambda 95614 too big: 277.4947368420091\n",
      "lambda 95660 too big: -205.15789473669918\n",
      "lambda 95919 too big: -206.35789473670235\n",
      "lambda 99017 too big: 605.9210526311425\n",
      "lambda 99185 too big: 253.21578947358466\n",
      "lambda 99357 too big: 261.3947368419182\n",
      "lambda 99396 too big: -298.7052631580125\n",
      "lambda 99825 too big: -206.25789473670204\n",
      "lambda 102187 too big: 364.8052631576033\n",
      "lambda 102199 too big: 697.2947368433073\n",
      "lambda 102651 too big: 668.8736842103526\n",
      "lambda 102991 too big: 680.1157894735977\n",
      "lambda 105270 too big: 761.2421052651991\n",
      "lambda 105773 too big: 248.4736842103892\n",
      "lambda 105782 too big: 363.1947368418843\n",
      "lambda 2419 too big: 959.5135354268202\n",
      "lambda 2535 too big: 201.01194859984264\n",
      "lambda 3020 too big: 536.1696511987899\n",
      "lambda 4199 too big: 277.1826552019686\n",
      "lambda 11325 too big: 210.098366290473\n",
      "lambda 11835 too big: 279.0364568573993\n",
      "lambda 13379 too big: 208.0569020866408\n",
      "lambda 14062 too big: 387.9872458131823\n",
      "lambda 16446 too big: 332.1779256564337\n",
      "lambda 19370 too big: 246.0915357806751\n",
      "lambda 19725 too big: 374.70378059796155\n",
      "lambda 28574 too big: 221.6789206814331\n",
      "lambda 33491 too big: 296.8288951823126\n",
      "lambda 33503 too big: 246.0915357806751\n",
      "lambda 34663 too big: 222.71486866534894\n",
      "lambda 37875 too big: 306.2728861057914\n",
      "lambda 42843 too big: 306.2208985083571\n",
      "lambda 42996 too big: 332.1766576662452\n",
      "lambda 46313 too big: 320.383080923877\n",
      "lambda 49100 too big: 224.5192187038545\n",
      "lambda 50482 too big: 257.4527278696122\n",
      "lambda 52937 too big: 290.69689463110944\n",
      "lambda 59811 too big: 398.84758177682727\n",
      "lambda 65345 too big: 503.62287904104795\n",
      "lambda 71262 too big: 623.6153265575928\n",
      "lambda 74660 too big: 328.29914367001675\n",
      "lambda 85973 too big: 320.383080923877\n",
      "lambda 89084 too big: 240.76090502832724\n",
      "lambda 92400 too big: 290.69689463110944\n",
      "lambda 95082 too big: 380.79266948298846\n",
      "lambda 95097 too big: 306.7065387503957\n",
      "lambda 95143 too big: 231.75183473969\n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 1: neg. log cond. likelihood = 714183.1850993037 [4 calls to valueAt]\n",
      "Iter 1 evals 1 <D> [11M 5.831E-5] 7.142E5 9.13s |6.020E4| {5.766E-1} 0.000E0 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 2: neg. log cond. likelihood = 574916.9190711351 [5 calls to valueAt]\n",
      "Iter 2 evals 4 <D> [M 1.000E0] 5.749E5 12.57s |6.677E4| {6.395E-1} 1.211E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 3: neg. log cond. likelihood = 447904.6925089675 [6 calls to valueAt]\n",
      "Iter 3 evals 5 <D> [M 1.000E0] 4.479E5 15.99s |2.604E4| {2.494E-1} 1.982E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 4: neg. log cond. likelihood = 390744.316400408 [7 calls to valueAt]\n",
      "Iter 4 evals 6 <D> [M 1.000E0] 3.907E5 19.38s |1.907E4| {1.826E-1} 2.069E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 5: neg. log cond. likelihood = 334949.85809320136 [8 calls to valueAt]\n",
      "Iter 5 evals 7 <D> [M 1.000E0] 3.349E5 22.74s |2.592E4| {2.482E-1} 2.264E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 6: neg. log cond. likelihood = 296574.82400680706 [9 calls to valueAt]\n",
      "Iter 6 evals 8 <D> [M 1.000E0] 2.966E5 26.07s |1.316E4| {1.260E-1} 2.347E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 7: neg. log cond. likelihood = 260745.30827621062 [10 calls to valueAt]\n",
      "Iter 7 evals 9 <D> [M 1.000E0] 2.607E5 29.40s |1.035E4| {9.914E-2} 2.484E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 8: neg. log cond. likelihood = 226118.1245699675 [11 calls to valueAt]\n",
      "Iter 8 evals 10 <D> [M 1.000E0] 2.261E5 32.79s |9.378E3| {8.982E-2} 2.698E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 9: neg. log cond. likelihood = 200158.00292835513 [12 calls to valueAt]\n",
      "Iter 9 evals 11 <D> [M 1.000E0] 2.002E5 36.58s |1.012E4| {9.690E-2} 2.853E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 10: neg. log cond. likelihood = 190136.57724893707 [14 calls to valueAt]\n",
      "Iter 10 evals 12 <D> [1M 4.620E-1] 1.901E5 43.02s |9.504E3| {9.102E-2} 2.756E-1 - \n",
      "class edu.stanford.nlp.maxent.CGRunner\n",
      "Iter. 11: neg. log cond. likelihood = 179227.96681191106 [15 calls to valueAt]\n",
      "Iter 11 evals 14 <D> [M 1.000E0] 1.792E5 46.56s |4.951E3| {4.741E-2} 2.208E-1 - \n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Expérience 2: Entraîner le modèle, recherche cg\n",
    "! java \\\n",
    "    -cp stanford-postagger.jar     edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -props labo_hyper_parameter_2.props \\\n",
    "    -nthreads 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3168433626.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_140141/3168433626.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle 1 sur le corpus de développement\n",
    "! java \\\n",
    "    -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment1.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-dev.conllu3 \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle 1 sur le corpus de test\n",
    "! java -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment1.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-test.conllu3 \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle 2 sur le corpus de développement\n",
    "! java -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment2.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-dev.conllu3 \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle 2 sur le corpus de test\n",
    "! java -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment2.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-test.conllu3 \\ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "train_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-train.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "dev_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-dev.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "test_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-test.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "corpuses = {'train': train_corpus, 'dev': dev_corpus, 'test': test_corpus}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Cesc chiffres sont-ils identiques à ceux obtenus pour `dev`et pour `test` à la fin de la Partie 1 ?  On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "\n",
    "\n",
    "for corpus_name, corpus in corpuses.items():\n",
    "    print(f\"{corpus_name} : {len(corpus.tagged_sents())} phrases, {len(corpus.tagged_words())} mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "print(\"17e phrase du corpus de développement :\")\n",
    "print(train_corpus.tagged_sents()[16])\n",
    "\n",
    "print(\"1001e à 1050e mots du corpus de test :\")\n",
    "print(test_corpus.tagged_words()[1001:1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = \"perceptron_model.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "%%timeit\n",
    "ptagger.train(train_corpus.tagged_sents(), MODEL_FILE, nr_iter=5)\n",
    "\n",
    "# TODO : demander si il y a d'autres hyper paramètres que nr_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule (en commentaires).\n",
    "# Avec 5 itérations, l'entraînement prend environ 1 minute\n",
    "# Le modèle fait 8 Mo\n",
    "! du -h perceptron_model.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "\n",
    "ptagger.load(MODEL_FILE)\n",
    "prediction = ptagger.tag(test_corpus.words())\n",
    "\n",
    "# https://www.nltk.org/api/nltk.tag.api.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Matrice de confusion et accuracy sur le corpus de dev : \")\n",
    "print(ptagger.confusion(dev_corpus.tagged_sents()))\n",
    "print(ptagger.accuracy(dev_corpus.tagged_sents()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Matrice de confusion et accuracy sur le corpus de test : \")\n",
    "print(ptagger.confusion(test_corpus.tagged_sents()))\n",
    "print(ptagger.accuracy(test_corpus.tagged_sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt | MaxEnt   | Avg Perceptron | \n",
    "|--------|--------|----------|---------------|\n",
    "| -      | fourni | entraîné | entraîné |\n",
    "| dev    |   ..   |   ..     |  ..  |\n",
    "| test   |   ..   |   ..     |  ..  |\n",
    "\n",
    "Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le rendre via Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
