{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger l'archive `UD_French-GSD-withBlankLines.zip` fournie sur Cyberlearn.\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu des colonnes :\n",
      "     Colonne 0 : Index\n",
      "     Colonne 1 : Token\n",
      "     Colonne 2 : Lemma\n",
      "     Colonne 3 : POS\n",
      "Liste des POS TAGS du projet Universal Dependencies:\n",
      "https://universaldependencies.org/u/pos/\n",
      "Format des fichiers du projet Universal Dependencies:\n",
      "https://universaldependencies.org/format.html\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule.\n",
    "cols = {'0': 'Index', '1': 'Token', '2': 'Lemma', '3': 'POS'}\n",
    "url_pos = \"https://universaldependencies.org/u/pos/\"\n",
    "url_format = \"https://universaldependencies.org/format.html\"\n",
    "\n",
    "print(\"Contenu des colonnes :\")\n",
    "\n",
    "for key, value in cols.items():\n",
    "    print(\"     Colonne\", key, \":\", value)\n",
    "\n",
    "print(\"Liste des POS TAGS du projet Universal Dependencies:\")\n",
    "print(url_pos)\n",
    "\n",
    "print(\"Format des fichiers du projet Universal Dependencies:\")\n",
    "print(url_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "              Corpus d'entraînement               \n",
      "__________________________________________________\n",
      "    Il y a 366371 tokens dans ce corpus.\n",
      "    Il y a 14554 phrases dans ce corpus.\n",
      "__________________________________________________\n",
      "             Corpus de développement              \n",
      "__________________________________________________\n",
      "    Il y a 36830 tokens dans ce corpus.\n",
      "    Il y a 1478 phrases dans ce corpus.\n",
      "__________________________________________________\n",
      "                  Corpus de test                  \n",
      "__________________________________________________\n",
      "    Il y a 10298 tokens dans ce corpus.\n",
      "    Il y a 416 phrases dans ce corpus.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "\n",
    "# Utilitaire pour afficher un titre\n",
    "def print_title(str, char, size):\n",
    "    print(f\"{'':{char}^{size}}\")\n",
    "    print(f\"{str:^{size}}\")\n",
    "    print(f\"{'':{char}^{size}}\")\n",
    "\n",
    "# Fichiers de travail\n",
    "file_location = 'UD_French-GSD-withBlankLines'\n",
    "file_train = 'fr-ud-train.conllu3'\n",
    "file_dev = 'fr-ud-dev.conllu3'\n",
    "file_test = 'fr-ud-test.conllu3'\n",
    "\n",
    "# Lecture des fichiers\n",
    "columnsIgnore = ('ignore', 'words', 'ignore', 'pos')\n",
    "train_corpus = ConllCorpusReader(file_location, file_train, columntypes=columnsIgnore, separator='\\t')\n",
    "dev_corpus = ConllCorpusReader(file_location, file_dev, columntypes=columnsIgnore, separator='\\t')\n",
    "test_corpus = ConllCorpusReader(file_location, file_test, columntypes=columnsIgnore, separator='\\t')\n",
    "corpuses = {'train': train_corpus, 'dev': dev_corpus, 'test': test_corpus}\n",
    "\n",
    "print_title(\"Corpus d'entraînement\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['train'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['train'].sents())} phrases dans ce corpus.\")\n",
    "print_title(\"Corpus de développement\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['dev'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['dev'].sents())} phrases dans ce corpus.\")\n",
    "print_title(\"Corpus de test\", \"_\", 50)\n",
    "print(f\"    Il y a {len(corpuses['test'].words())} tokens dans ce corpus.\")\n",
    "print(f\"    Il y a {len(corpuses['test'].sents())} phrases dans ce corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "\n",
    "tokens_dev = [word for word in dev_corpus.words()]\n",
    "tokens_test = [word for word in test_corpus.words()]\n",
    "tokens_train = [word for word in train_corpus.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LazyMap' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_134402/128552691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpuses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyMap' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "st = StanfordPOSTagger('french-ud.tagger', 'stanford-postagger.jar')\n",
    "\n",
    "# demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. \n",
    "pred = st.tag(tokens_dev)\n",
    "y_true = corpuses['dev'].tagged_sents()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "pred = st.tag(tokens_test)\n",
    "y_true = corpuses['test'].tagged_sents()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiaire** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "              Corpus d'entraînement               \n",
      "__________________________________________________\n",
      "Il y a 36830 mots dans le corpus de développement.\n",
      "Il y a 1478 phrases dans le corpus de développement.\n",
      "__________________________________________________\n",
      "                  Corpus de test                  \n",
      "__________________________________________________\n",
      "Il y a 10298 mots dans le corpus de test.\n",
      "Il y a 416 phrases dans le corpus de test.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire vos réponses ci-dessous, en commentaires\n",
    "print_title(\"Corpus d'entraînement\", \"_\", 50)\n",
    "print(f\"Il y a {len(corpuses['dev'].words())} mots dans le corpus de développement.\")\n",
    "print(f\"Il y a {len(corpuses['dev'].sents())} phrases dans le corpus de développement.\")\n",
    "print_title(\"Corpus de test\", \"_\", 50)\n",
    "print(f\"Il y a {len(corpuses['test'].words())} mots dans le corpus de test.\")\n",
    "print(f\"Il y a {len(corpuses['test'].sents())} phrases dans le corpus de test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "! java \\\n",
    "    -cp stanford-postagger.jar     edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -props labo_hyper_parameter_1.props \\\n",
    "    -nthreads 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! java \\\n",
    "    -cp stanford-postagger.jar     edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -props labo_hyper_parameter_2.props \\\n",
    "    -nthreads 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "# mx1g = 1 gigabyte de mémoire allouée\n",
    "! java -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment1.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-dev.conllu3 \\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! java -mx1g \\ \n",
    "    -cp edu.stanford.nlp.tagger.maxent.MaxentTagger \\\n",
    "    -model experiment2.tagger \\\n",
    "    -testFile UD_French-GSD_withBlankLines/fr-ud-dev.conllu3 \\ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "train_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-train.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "dev_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-dev.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "test_corpus = ConllCorpusReader(\"UD_French-GSD-withBlankLines\", \"fr-ud-test.conllu3\", columntypes=('ignore', 'words', 'ignore', 'pos'), separator='\\t')\n",
    "corpuses = {'train': train_corpus, 'dev': dev_corpus, 'test': test_corpus}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Cesc chiffres sont-ils identiques à ceux obtenus pour `dev`et pour `test` à la fin de la Partie 1 ?  On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "\n",
    "\n",
    "for corpus_name, corpus in corpuses.items():\n",
    "    print(f\"{corpus_name} : {len(corpus.tagged_sents())} phrases, {len(corpus.tagged_words())} mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "print(\"17e phrase du corpus de développement :\")\n",
    "print(train_corpus.tagged_sents()[16])\n",
    "\n",
    "print(\"1001e à 1050e mots du corpus de test :\")\n",
    "print(test_corpus.tagged_words()[1001:1050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = \"perceptron_model.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "%%timeit\n",
    "ptagger.train(train_corpus.tagged_sents(), MODEL_FILE, nr_iter=5)\n",
    "\n",
    "# TODO : demander si il y a d'autres hyper paramètres que nr_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule (en commentaires).\n",
    "# Avec 5 itérations, l'entraînement prend environ 1 minute\n",
    "# Le modèle fait 8 Mo\n",
    "! du -h perceptron_model.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "\n",
    "\n",
    "ptagger.load(MODEL_FILE)\n",
    "prediction = ptagger.tag(test_corpus.words())\n",
    "\n",
    "# https://www.nltk.org/api/nltk.tag.api.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Matrice de confusion et accuracy sur le corpus de dev : \")\n",
    "print(ptagger.confusion(dev_corpus.tagged_sents()))\n",
    "print(ptagger.accuracy(dev_corpus.tagged_sents()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Matrice de confusion et accuracy sur le corpus de test : \")\n",
    "print(ptagger.confusion(test_corpus.tagged_sents()))\n",
    "print(ptagger.accuracy(test_corpus.tagged_sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt | MaxEnt   | Avg Perceptron | \n",
    "|--------|--------|----------|---------------|\n",
    "| -      | fourni | entraîné | entraîné |\n",
    "| dev    |   ..   |   ..     |  ..  |\n",
    "| test   |   ..   |   ..     |  ..  |\n",
    "\n",
    "Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, sauvegarder le résultat, et le rendre via Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
